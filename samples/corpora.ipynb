{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Corpora Tutorial\n",
    "\n",
    "In this notebook, we will demonstrate how to use Machine to load datasets as text corpora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Text Files\n",
    "\n",
    "Let's start with a simple example of loading a set of text files. Every text corpus class requires a tokenizer. Our text corpus has already been tokenized. The tokens are delimited using whitespace, so we will use the `WhitespaceTokenizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from machine.corpora import TextFileTextCorpus\n",
    "from machine.tokenization import WhitespaceTokenizer\n",
    "\n",
    "tokenizer = WhitespaceTokenizer()\n",
    "corpus = TextFileTextCorpus(tokenizer, \"data/en_tok.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is easy to iterate through the sentences in the corpus. We simply call the `get_segments` method on the corpus class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I would like to book a room until tomorrow , please .\n",
      "Please wake us up tomorrow at a quarter past seven .\n",
      "I am leaving today in the afternoon .\n",
      "Would you mind sending down our luggage to room number oh one three , please ?\n",
      "Could you give me the key to room number two four four , please ?\n",
      "Are there a tv , air conditioning and a safe in the rooms ?\n",
      "We are leaving on the eighth at half past seven in the afternoon .\n",
      "I want a single room for this week , please .\n",
      "I would like you to give us the keys to the room .\n",
      "I have made a reservation for a quiet , single room with a view of the mountain and a shower for Carmen Aguilera .\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "for text_segment in islice(corpus.get_segments(), 10):\n",
    "    print(\" \".join(text_segment.segment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Scripture\n",
    "\n",
    "Machine contains classes for loading Scripture in various formats, such as USFM and USX."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### USX\n",
    "\n",
    "USX is a common XML format for Scripture. Let's take a look at how to load a set of USX files. First, we create an instance of the `UsxFileTextCorpus` class. We ensure that the correct verse references are used by loading the versification file for this translation. If a versification is not provided, then the English versification is used. We want untokenized verse text, so we use the `NullTokenizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from machine.corpora import UsxFileTextCorpus\n",
    "from machine.scripture import Versification\n",
    "from machine.tokenization import NullTokenizer\n",
    "\n",
    "tokenizer = NullTokenizer()\n",
    "versification = Versification.load(\"data/WEB-DBL/release/versification.vrs\", fallback_name=\"web\")\n",
    "corpus = UsxFileTextCorpus(tokenizer, \"data/WEB-DBL/release/USX_1\", versification=versification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's iterate through the corpus. You will notice that each text segment in the corpus has an associated reference. In the case of Scripture, these are `VerseRef` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1JN 1:1: That which was from the beginning, that which we have heard, that which we have seen with our eyes, that which we saw, and our hands touched, concerning the Word of life\n",
      "1JN 1:2: (and the life was revealed, and we have seen, and testify, and declare to you the life, the eternal life, which was with the Father, and was revealed to us);\n",
      "1JN 1:3: that which we have seen and heard we declare to you, that you also may have fellowship with us. Yes, and our fellowship is with the Father and with his Son, Jesus Christ.\n",
      "1JN 1:4: And we write these things to you, that our joy may be fulfilled.\n",
      "1JN 1:5: This is the message which we have heard from him and announce to you, that God is light, and in him is no darkness at all.\n",
      "1JN 1:6: If we say that we have fellowship with him and walk in the darkness, we lie and don’t tell the truth.\n",
      "1JN 1:7: But if we walk in the light as he is in the light, we have fellowship with one another, and the blood of Jesus Christ his Son, cleanses us from all sin.\n",
      "1JN 1:8: If we say that we have no sin, we deceive ourselves, and the truth is not in us.\n",
      "1JN 1:9: If we confess our sins, he is faithful and righteous to forgive us the sins and to cleanse us from all unrighteousness.\n",
      "1JN 1:10: If we say that we haven’t sinned, we make him a liar, and his word is not in us.\n"
     ]
    }
   ],
   "source": [
    "for text_segment in islice(corpus.get_segments(), 10):\n",
    "    verse_ref_str = str(text_segment.segment_ref)\n",
    "    verse_text = \" \".join(text_segment.segment)\n",
    "    print(f\"{verse_ref_str}: {verse_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also iterate through verses in the corpus by book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1JN\n",
      "======\n",
      "1:1: That which was from the beginning, that which we have heard, that which we have seen with our eyes, that which we saw, and our hands touched, concerning the Word of life\n",
      "1:2: (and the life was revealed, and we have seen, and testify, and declare to you the life, the eternal life, which was with the Father, and was revealed to us);\n",
      "1:3: that which we have seen and heard we declare to you, that you also may have fellowship with us. Yes, and our fellowship is with the Father and with his Son, Jesus Christ.\n",
      "\n",
      "2JN\n",
      "======\n",
      "1:1: The elder, to the chosen lady and her children, whom I love in truth, and not I only, but also all those who know the truth,\n",
      "1:2: for the truth’s sake, which remains in us, and it will be with us forever:\n",
      "1:3: Grace, mercy, and peace will be with us, from God the Father and from the Lord Jesus Christ, the Son of the Father, in truth and love.\n",
      "\n",
      "3JN\n",
      "======\n",
      "1:1: The elder to Gaius the beloved, whom I love in truth.\n",
      "1:2: Beloved, I pray that you may prosper in all things and be healthy, even as your soul prospers.\n",
      "1:3: For I rejoiced greatly when brothers came and testified about your truth, even as you walk in truth.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for text in corpus.texts:\n",
    "    print(text.id)\n",
    "    print(\"======\")\n",
    "    for text_segment in islice(text.get_segments(), 3):\n",
    "        verse_ref = text_segment.segment_ref\n",
    "        chapter_verse = f\"{verse_ref.chapter}:{verse_ref.verse}\"\n",
    "        verse_text = \" \".join(text_segment.segment)\n",
    "        print(f\"{chapter_verse}: {verse_text}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digital Bible Library Bundles\n",
    "\n",
    "Now, let's load a Digital Bible Library (DBL) bundle. A DBL bundle is a zip archive that contains all of the data that you need for a publishable Bible translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DBL bundle created.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.make_archive(\"out/web\", \"zip\", \"data/WEB-DBL\");\n",
    "print(\"DBL bundle created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create a `DblBundleTextCorpus` instance. This time we want to tokenize the text, so we use the `LatinWordTokenizer`, a good default tokenizer for languages with Latin-based scripts. There is no need to specify versification, because the `DblBundleTextCorpus` class takes care of that for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from machine.tokenization import LatinWordTokenizer\n",
    "from machine.corpora import DblBundleTextCorpus\n",
    "\n",
    "tokenizer = LatinWordTokenizer()\n",
    "corpus = DblBundleTextCorpus(tokenizer, \"out/web.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can iterate through the corpus just as we did before. All text corpus classes in Machine adhere to the same interface, so it is easy to switch between the various classes. Also, you can see that the verse text is nicely tokenized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1JN 1:1: That which was from the beginning , that which we have heard , that which we have seen with our eyes , that which we saw , and our hands touched , concerning the Word of life\n",
      "1JN 1:2: ( and the life was revealed , and we have seen , and testify , and declare to you the life , the eternal life , which was with the Father , and was revealed to us ) ;\n",
      "1JN 1:3: that which we have seen and heard we declare to you , that you also may have fellowship with us . Yes , and our fellowship is with the Father and with his Son , Jesus Christ .\n",
      "1JN 1:4: And we write these things to you , that our joy may be fulfilled .\n",
      "1JN 1:5: This is the message which we have heard from him and announce to you , that God is light , and in him is no darkness at all .\n",
      "1JN 1:6: If we say that we have fellowship with him and walk in the darkness , we lie and don’t tell the truth .\n",
      "1JN 1:7: But if we walk in the light as he is in the light , we have fellowship with one another , and the blood of Jesus Christ his Son , cleanses us from all sin .\n",
      "1JN 1:8: If we say that we have no sin , we deceive ourselves , and the truth is not in us .\n",
      "1JN 1:9: If we confess our sins , he is faithful and righteous to forgive us the sins and to cleanse us from all unrighteousness .\n",
      "1JN 1:10: If we say that we haven’t sinned , we make him a liar , and his word is not in us .\n"
     ]
    }
   ],
   "source": [
    "for text_segment in islice(corpus.get_segments(), 10):\n",
    "    verse_ref_str = str(text_segment.segment_ref)\n",
    "    verse_text = \" \".join(text_segment.segment)\n",
    "    print(f\"{verse_ref_str}: {verse_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paratext Projects\n",
    "\n",
    "Another useful text corpus class is `ParatextTextCorpus`. This class is used to load a Paratext project. It properly loads the configured encoding and versification for the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from machine.corpora import ParatextTextCorpus\n",
    "\n",
    "corpus = ParatextTextCorpus(tokenizer, \"data/WEB-PT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's iterate through the segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1JN 1:1: That which was from the beginning , that which we have heard , that which we have seen with our eyes , that which we saw , and our hands touched , concerning the Word of life\n",
      "1JN 1:2: ( and the life was revealed , and we have seen , and testify , and declare to you the life , the eternal life , which was with the Father , and was revealed to us ) ;\n",
      "1JN 1:3: that which we have seen and heard we declare to you , that you also may have fellowship with us . Yes , and our fellowship is with the Father and with his Son , Jesus Christ .\n",
      "1JN 1:4: And we write these things to you , that our joy may be fulfilled .\n",
      "1JN 1:5: This is the message which we have heard from him and announce to you , that God is light , and in him is no darkness at all .\n",
      "1JN 1:6: If we say that we have fellowship with him and walk in the darkness , we lie and don’t tell the truth .\n",
      "1JN 1:7: But if we walk in the light as he is in the light , we have fellowship with one another , and the blood of Jesus Christ his Son , cleanses us from all sin .\n",
      "1JN 1:8: If we say that we have no sin , we deceive ourselves , and the truth is not in us .\n",
      "1JN 1:9: If we confess our sins , he is faithful and righteous to forgive us the sins and to cleanse us from all unrighteousness .\n",
      "1JN 1:10: If we say that we haven’t sinned , we make him a liar , and his word is not in us .\n"
     ]
    }
   ],
   "source": [
    "for text_segment in islice(corpus.get_segments(), 10):\n",
    "    verse_ref = str(text_segment.segment_ref)\n",
    "    verse_text = \" \".join(text_segment.segment)\n",
    "    print(f\"{verse_ref}: {verse_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Processors\n",
    "\n",
    "Often tokenized text must be processed in some way as a part of a AI/ML pipeline. Machine has a set of token processors that can be used to process text segments easily. Lowercasing text is a common pre-processing step, so let's show how to apply the `LOWERCASE` token processor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new york is cold in the winter .\n"
     ]
    }
   ],
   "source": [
    "from machine.corpora import LOWERCASE\n",
    "\n",
    "sentence = \"New York is cold in the Winter .\".split()\n",
    "print(\" \".join(LOWERCASE.process(sentence)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple token processors can be applied in sequence using the `pipeline` function. Here we will lowercase a segment and normalize it to NFC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of decomposed Åström is 8.\n",
      "The length of precomposed åström is 6.\n"
     ]
    }
   ],
   "source": [
    "from machine.corpora import pipeline, NFC_NORMALIZE\n",
    "\n",
    "sentence = \"Here is a decomposed Swedish name Åström .\".split()\n",
    "print(f\"The length of decomposed {sentence[6]} is {len(sentence[6])}.\")\n",
    "sentence = pipeline(NFC_NORMALIZE, LOWERCASE).process(sentence)\n",
    "print(f\"The length of precomposed {sentence[6]} is {len(sentence[6])}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Text Corpora\n",
    "\n",
    "So far we have only dealt with monolingual corpora. For many tasks, such as machine translation, parallel corpora are required. Machine provides a corpus class for combining two monolingual corpora into a parallel corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create a parallel text corpus, we must first create the source and target monolingual text corpora. Then, we can create the `ParallelTextCorpus` object from the monolingual corpus objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from machine.corpora import ParallelTextCorpus\n",
    "\n",
    "source_corpus = ParatextTextCorpus(tokenizer, \"data/VBL-PT\")\n",
    "target_corpus = ParatextTextCorpus(tokenizer, \"data/WEB-PT\")\n",
    "parallel_corpus = ParallelTextCorpus(source_corpus, target_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now iterate through the parallel segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1JN 1:1\n",
      "Source: Esta carta trata sobre la Palabra de vida que existía desde el principio , que hemos escuchado , que hemos visto con nuestros propios ojos y le hemos contemplado , y que hemos tocado con nuestras manos .\n",
      "Target: That which was from the beginning , that which we have heard , that which we have seen with our eyes , that which we saw , and our hands touched , concerning the Word of life\n",
      "1JN 1:2\n",
      "Source: Esta Vida nos fue revelada . La vimos y damos testimonio de ella . Estamos hablándoles de Aquél que es la Vida Eterna , que estaba con el Padre , y que nos fue revelado .\n",
      "Target: ( and the life was revealed , and we have seen , and testify , and declare to you the life , the eternal life , which was with the Father , and was revealed to us ) ;\n",
      "1JN 1:3\n",
      "Source: Los que hemos visto y oído eso mismo les contamos , para que también puedan participar de esta amistad junto a nosotros . Esta amistad con el Padre y su Hijo Jesucristo .\n",
      "Target: that which we have seen and heard we declare to you , that you also may have fellowship with us . Yes , and our fellowship is with the Father and with his Son , Jesus Christ .\n",
      "1JN 1:4\n",
      "Source: Escribimos para decirles esto , a fin de que nuestra felicidad sea completa .\n",
      "Target: And we write these things to you , that our joy may be fulfilled .\n",
      "1JN 1:5\n",
      "Source: Este es el mensaje que recibimos de él y que nosotros les declaramos a ustedes : Dios es luz , y no hay ningún vestigio de oscuridad en él .\n",
      "Target: This is the message which we have heard from him and announce to you , that God is light , and in him is no darkness at all .\n"
     ]
    }
   ],
   "source": [
    "for text_segment in islice(parallel_corpus.get_segments(), 5):\n",
    "    verse_ref_str = str(text_segment.segment_ref)\n",
    "    source_verse_text = \" \".join(text_segment.source_segment)\n",
    "    target_verse_text = \" \".join(text_segment.target_segment)\n",
    "    print(verse_ref_str)\n",
    "    print(\"Source:\", source_verse_text)\n",
    "    print(\"Target:\", target_verse_text)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e5c3594217c843d98647b94b941817aced8bb402b4624bfdbaebf1a3617786b5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('sil-machine-hNQycPie-py3.7': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
